{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rsvMJ1t0hF3"
      },
      "source": [
        "### ***Joseph Leandre Derpo 63110107***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGAYRlym0hF8"
      },
      "source": [
        "#### ***MNIST 14-layered CNN model with 99% accuracy***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLzCc_n7oTLE",
        "outputId": "490794a5-fe4b-4318-b03b-80f039920812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ],
      "source": [
        "# Libraries \n",
        "%reset \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import Model, layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,BatchNormalization,Flatten,Dropout\n",
        "\n",
        "# Settin random seed to obtain the same results\n",
        "np.random.seed(3632)\n",
        "random.seed(3632)\n",
        "tf.random.set_seed(3632)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTgHxQ6L0hGC",
        "outputId": "53d27ba0-ab02-4a8d-fcfa-503564a2abba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST Dataset Shapes:\n",
            "x_train: (60000, 28, 28, 1)\n",
            "y_train: (60000,)\n",
            "x_test: (10000, 28, 28, 1)\n",
            "y_test: (10000,)\n",
            "Image Dimension: (28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# preparation of MNIST dataset\n",
        "\n",
        "# parameters of MNIST dataset\n",
        "num_classes = 10 # total classes (0-9 digits)\n",
        "num_features = 784 # data features (img shape: 28 X 28 = 784)\n",
        "\n",
        "# import and load MNIST data, split between and test datasets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# convert pixel values to float32\n",
        "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
        "\n",
        "# normalize image pixcel values from [0, 255] to [0, 1]\n",
        "x_train, x_test = x_train / 255., x_test / 255.\n",
        "\n",
        "# data should be 4D so setting gray scale color channel is necessary to make it work with Conv2D\n",
        "x_train, x_test = np.expand_dims(x_train, axis=-1), np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# check shape of MNIST dataset\n",
        "print('MNIST Dataset Shapes:')\n",
        "print(f'x_train: {str(x_train.shape)}')\n",
        "print(f'y_train: {str(y_train.shape)}')\n",
        "print(f'x_test: {str(x_test.shape)}')\n",
        "print(f'y_test: {str(y_test.shape)}')\n",
        "\n",
        "# determine the shape of the input images\n",
        "inp_shape = x_train.shape[1:]\n",
        "print(f'Image Dimension: {inp_shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "WBL-zajDsqGd"
      },
      "outputs": [],
      "source": [
        "# training parameters\n",
        "learning_rate = 0.1\n",
        "training_epochs = 2000\n",
        "batch_size = 256\n",
        "display_step = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "2sfvAxPt0hGH"
      },
      "outputs": [],
      "source": [
        "# network parameters\n",
        "n_hidden_1 = 32 # 1st hidden layer number of neurons\n",
        "n_hidden_2 = 64 # 2nd hidden layer number of neurons\n",
        "n_hidden_3 = 128 # 3nd hidden layer number of neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "44nSIJUh0hGJ"
      },
      "outputs": [],
      "source": [
        "# use tf.data API to shuffle and batch data\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Du0SbgZ30hGL"
      },
      "outputs": [],
      "source": [
        "# MNIST CNN architecture\n",
        "class ConvNeuralNetwork(Model):\n",
        "\n",
        "    # set layers\n",
        "    def __init__(self):\n",
        "        super(ConvNeuralNetwork, self).__init__()\n",
        "\n",
        "        self.model = Sequential()\n",
        "\n",
        "        # first CNN layer\n",
        "        self.model.add(layers.Conv2D(n_hidden_1, (3,3), activation = tf.nn.relu, kernel_initializer='he_uniform'))\n",
        "        self.model.add(layers.BatchNormalization()) # normalize the input layer as well as hidden layers by adjusting mean and scaling of the activations\n",
        "        self.model.add(layers.MaxPool2D(2,2)) # downsample data to half to make it faster\n",
        "        self.model.add(layers.Dropout(0.5)) # dropout to make the model less rely on weight to prevent overfitting\n",
        "        \n",
        "        # second CNN layer\n",
        "        self.model.add(layers.Conv2D(n_hidden_2, (3,3), activation=tf.nn.relu, kernel_initializer='he_uniform'))\n",
        "        self.model.add(layers.BatchNormalization())\n",
        "        self.model.add(layers.MaxPool2D((2,2)))\n",
        "        self.model.add(layers.Dropout(0.5))\n",
        "\n",
        "        # third CNN layer\n",
        "        self.model.add(layers.Conv2D(n_hidden_3, (3,3), activation=tf.nn.relu, kernel_initializer='he_uniform'))\n",
        "        self.model.add(layers.BatchNormalization())\n",
        "        self.model.add(layers.Dropout(0.5))\n",
        "\n",
        "        self.model.add(layers.Flatten())  # flatten features into a single column\n",
        "        self.model.add(layers.Dense(units = 64, activation=tf.nn.relu))\n",
        "\n",
        "        # output layer\n",
        "        self.model.add(layers.Dense(units = num_classes)) # combine to 10 classes\n",
        "    \n",
        "    # set forward pass\n",
        "    def call(self, x, is_training = False):    \n",
        "        \n",
        "        x = self.model(x)\n",
        "\n",
        "        if not is_training:\n",
        "            \n",
        "            # tf cross entropy expect logits without softmax, so only\n",
        "            # apply softmax when not training.\n",
        "            tf.nn.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "pezjQp2XrGjv"
      },
      "outputs": [],
      "source": [
        "# build convolutional neural network model\n",
        "c_neural_net = ConvNeuralNetwork()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "QEpuKEBv0hGR"
      },
      "outputs": [],
      "source": [
        "# initialize variables with Xavier uniform\n",
        "shape = (num_features, num_classes)\n",
        "initializer = tf.initializers.GlorotUniform()\n",
        "trainable_variables = tf.Variable(initializer(shape = shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "_ONlswN0PvT0"
      },
      "outputs": [],
      "source": [
        "# Cross-Entropy loss - applies 'softmax' to the logits \n",
        "def cross_entropy_loss(x, y):\n",
        "    \n",
        "  # convert labels to int 64 for tf cross-entropy function\n",
        "  y = tf.cast(y, tf.int64)\n",
        "    \n",
        "  # apply softmax to logits and compute cross-entropy\n",
        "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = x)\n",
        "    \n",
        "  # average loss across the batch\n",
        "  return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "hvtTe7-V0hGU"
      },
      "outputs": [],
      "source": [
        "# accuracy metric\n",
        "def accuracy(y_pred, y_true):\n",
        "    \n",
        "  # predicted class is the index of highest score in prediction vector (i.e. argmax)\n",
        "  correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "\n",
        "  return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "ETHn-nSRpaIM"
      },
      "outputs": [],
      "source": [
        "# Stochastic gradient descent optimizer\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "# set up an optimization (forward propagation and back propagation) process \n",
        "def run_optimization(x, y):\n",
        "    \n",
        "  # wrap computation inside a GradientTape for automatic differentiation\n",
        "  with tf.GradientTape() as g:\n",
        "        \n",
        "      # forward pass\n",
        "      pred = c_neural_net(x, is_training = True)\n",
        "        \n",
        "      # compute loss\n",
        "      loss = cross_entropy_loss(pred, y)\n",
        "        \n",
        "  # variables to update, i.e. trainable variables\n",
        "  trainable_variables = c_neural_net.trainable_variables\n",
        "\n",
        "  # compute gradients\n",
        "  gradients = g.gradient(loss, trainable_variables)\n",
        "    \n",
        "  # apply the gradients to update 𝜃 and 𝜃_0  \n",
        "  optimizer.apply_gradients(zip(gradients, trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgyorMPNQK2h",
        "outputId": "2ef6d3fa-d998-4b2e-dce8-71504164a341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 100, loss: 0.087886, accuracy: 0.976562\n",
            "step: 200, loss: 0.101792, accuracy: 0.972656\n",
            "step: 300, loss: 0.030348, accuracy: 0.992188\n",
            "step: 400, loss: 0.034139, accuracy: 0.996094\n",
            "step: 500, loss: 0.033693, accuracy: 0.992188\n",
            "step: 600, loss: 0.047705, accuracy: 0.988281\n",
            "step: 700, loss: 0.012480, accuracy: 1.000000\n",
            "step: 800, loss: 0.021395, accuracy: 0.992188\n",
            "step: 900, loss: 0.046927, accuracy: 0.980469\n",
            "step: 1000, loss: 0.011004, accuracy: 0.996094\n",
            "step: 1100, loss: 0.010681, accuracy: 1.000000\n",
            "step: 1200, loss: 0.003783, accuracy: 1.000000\n",
            "step: 1300, loss: 0.017030, accuracy: 0.996094\n",
            "step: 1400, loss: 0.014743, accuracy: 0.992188\n",
            "step: 1500, loss: 0.015837, accuracy: 0.992188\n",
            "step: 1600, loss: 0.004155, accuracy: 1.000000\n",
            "step: 1700, loss: 0.011605, accuracy: 0.996094\n",
            "step: 1800, loss: 0.015401, accuracy: 0.992188\n",
            "step: 1900, loss: 0.008604, accuracy: 1.000000\n",
            "step: 2000, loss: 0.003159, accuracy: 1.000000\n",
            "Test Accuracy:0.990000\n"
          ]
        }
      ],
      "source": [
        "# run training for the given number of steps\n",
        "for step, (batch_x, batch_y) in enumerate(train_data.take(training_epochs), 1):\n",
        "  run_optimization(batch_x, batch_y)\n",
        "\n",
        "  if step % display_step == 0:\n",
        "    pred = c_neural_net(batch_x, is_training = True)\n",
        "    loss = cross_entropy_loss(pred, batch_y)\n",
        "    acc = accuracy(pred, batch_y)\n",
        "    print(\"step: %i, loss: %f, accuracy: %f\" % (step,loss,acc))\n",
        "\n",
        "pred = c_neural_net(x_test, is_training = False)\n",
        "print(\"Test Accuracy:%f\" % accuracy(pred,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "5JTb0923lddj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "cb3d1fa7-a4bb-4a0d-9bdf-495e9733e2b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n",
            "Prediction: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# testing out the model to predict \n",
        "img = x_test[random.randint(0, 10000)]\n",
        "plt.imshow(np.squeeze(img), cmap='gray')\n",
        "\n",
        "img = img.reshape(1,img.shape[0],img.shape[1],img.shape[2])\n",
        "pred_val = c_neural_net.predict(img)\n",
        "print(\"Prediction:\",np.argmax(pred_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn model summary \n",
        "c_neural_net.model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljg6gCzx2x3L",
        "outputId": "f680a0a6-5554-4b13-8f43-8bc10ca5541d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 26, 26, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 13, 13, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 11, 11, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 3, 3, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 3, 3, 128)         0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                73792     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 168,010\n",
            "Trainable params: 167,562\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "c990fb971505e898a4244c427f98c1776e773deab4fc418a8390341fdacf822e"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}